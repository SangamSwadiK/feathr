{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feathr Feature Store on Azure Demo Notebook\n",
    "\n",
    "This notebook illustrates the use of Feature Store to create a model that predicts NYC Taxi fares. It includes these steps:\n",
    "\n",
    "\n",
    "This tutorial demonstrates the key capabilities of Feathr, including:\n",
    "\n",
    "1. Install and set up Feathr with Azure\n",
    "2. Create shareable features with Feathr feature definition configs.\n",
    "3. Create a training dataset via point-in-time feature join.\n",
    "4. Compute and write features.\n",
    "5. Train a model using these features to predict fares.\n",
    "6. Materialize feature value to online store.\n",
    "7. Fetch feature value in real-time from online store for online scoring.\n",
    "\n",
    "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi fares. The dataset comes from [here](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page). The feature flow is as below:\n",
    "\n",
    "![Feature Flow](https://github.com/linkedin/feathr/blob/main/docs/images/feature_flow.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Use Quick Start Template to Provision Azure Resources\n",
    "\n",
    "Feathr has native cloud integration. To use Feathr on Azure, you only need three steps:\n",
    "\n",
    "- Get the `Principal ID` of your account by running `az ad signed-in-user show --query objectId -o tsv` in the link below (Select \"Bash\" if asked), and write down that value (something like `b65ef2e0-42b8-44a7-9b55-abbccddeefff`). Think this ID as something representing you when accessing Azure, and it will be used to grant permissions in the next step in the UI.\n",
    "\n",
    "[Launch Cloud Shell](https://shell.azure.com/bash)\n",
    "\n",
    "- Click the button below to deploy a minimal set of Feathr resources for demo purpose. You will need to fill in the `Principal ID` and `Resource Prefix`. You will need \"Owner\" permission of the selected subscription.\n",
    "\n",
    "[![Deploy to Azure](https://aka.ms/deploytoazurebutton)](https://portal.azure.com/#create/Microsoft.Template/uri/https%3A%2F%2Fraw.githubusercontent.com%2Flinkedin%2Ffeathr%2Fmain%2Fdocs%2Fhow-to-guides%2Fazure_resource_provision.json)\n",
    "\n",
    "- Run the cells below.\n",
    "\n",
    "And the architecture is as below. In the above template, we are using Synapse as Spark provider, use Azure Data Lake Gen2 as offline store, and use Redis as online store, Azure Purview (Apache Atlas compatible) as feature reigstry. \n",
    "\n",
    "\n",
    "![Architecture](https://github.com/linkedin/feathr/blob/main/docs/images/architecture.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Install Feathr \n",
    "\n",
    "Install Feathr using pip:\n",
    "\n",
    "`pip install -U feathr pandavro scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Configure the required environment with Feathr Quick Start Template\n",
    "\n",
    "In the first step (Provision cloud resources), you should have provisioned all the required cloud resources. Run the code below to install Feathr, login to Azure to get the required credentials to access more cloud resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REQUIRED STEP: Fill in the resource prefix when provisioning the resources**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "resource_prefix = \"feathr_resource_prefix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feathr in /Users/hnlin/IdeaProjects/feathr_sample/feathr_project (0.4.0)\n",
      "Collecting azure-cli\n",
      "  Downloading azure_cli-2.36.0-py3-none-any.whl (2.4 MB)\n",
      "     |████████████████████████████████| 2.4 MB 9.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandavro in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (1.6.0)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.0.2-cp39-cp39-macosx_10_13_x86_64.whl (8.0 MB)\n",
      "Requirement already satisfied: Click in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (8.1.3)\n",
      "Requirement already satisfied: azure-storage-file-datalake>=12.5.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (12.6.0)\n",
      "Requirement already satisfied: azure-synapse-spark in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.7.0)\n",
      "Requirement already satisfied: azure-identity in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (1.10.0)\n",
      "Requirement already satisfied: py4j in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.10.9.3)\n",
      "Requirement already satisfied: loguru in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.6.0)\n",
      "Requirement already satisfied: pandas in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (1.4.2)\n",
      "Requirement already satisfied: redis in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (4.3.1)\n",
      "Requirement already satisfied: requests in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (2.27.1)\n",
      "Requirement already satisfied: pyapacheatlas in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.12.0)\n",
      "Requirement already satisfied: pyhocon in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.3.59)\n",
      "Requirement already satisfied: pyyaml in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (6.0)\n",
      "Requirement already satisfied: Jinja2 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (3.1.2)\n",
      "Requirement already satisfied: tqdm in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (4.64.0)\n",
      "Requirement already satisfied: pyarrow in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (8.0.0)\n",
      "Requirement already satisfied: pyspark>=3.1.2 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (3.2.1)\n",
      "Requirement already satisfied: python-snappy in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.6.1)\n",
      "Requirement already satisfied: deltalake in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.5.7)\n",
      "Requirement already satisfied: google>=3.0.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (3.0.0)\n",
      "Requirement already satisfied: graphlib_backport in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (1.0.3)\n",
      "Requirement already satisfied: google-api-python-client>=2.41.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (2.47.0)\n",
      "Requirement already satisfied: azure-keyvault-secrets in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (4.4.0)\n",
      "Requirement already satisfied: confluent-kafka in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (1.8.2)\n",
      "Requirement already satisfied: databricks-cli in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (0.16.6)\n",
      "Requirement already satisfied: avro in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (1.11.0)\n",
      "Requirement already satisfied: azure-core<=1.22.1 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (1.22.1)\n",
      "Requirement already satisfied: typing_extensions>=4.2.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from feathr) (4.2.0)\n",
      "Collecting azure-mgmt-trafficmanager~=1.0.0\n",
      "  Downloading azure_mgmt_trafficmanager-1.0.0-py3-none-any.whl (49 kB)\n",
      "     |████████████████████████████████| 49 kB 7.2 MB/s             \n",
      "\u001b[?25hCollecting azure-storage-common~=1.4\n",
      "  Using cached azure_storage_common-1.4.2-py2.py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli) (1.16.0)\n",
      "Collecting azure-multiapi-storage~=0.8.0\n",
      "  Downloading azure_multiapi_storage-0.8.0-py2.py3-none-any.whl (6.2 MB)\n",
      "     |████████████████████████████████| 6.2 MB 26.6 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-compute~=26.1.0\n",
      "  Downloading azure_mgmt_compute-26.1.0-py3-none-any.whl (4.8 MB)\n",
      "     |████████████████████████████████| 4.8 MB 35.7 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-deploymentmanager~=0.2.0\n",
      "  Downloading azure_mgmt_deploymentmanager-0.2.0-py2.py3-none-any.whl (41 kB)\n",
      "     |████████████████████████████████| 41 kB 620 kB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-managementgroups~=1.0.0\n",
      "  Downloading azure_mgmt_managementgroups-1.0.0-py2.py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 6.1 MB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-iothubprovisioningservices==1.1.0\n",
      "  Downloading azure_mgmt_iothubprovisioningservices-1.1.0-py3-none-any.whl (52 kB)\n",
      "     |████████████████████████████████| 52 kB 2.7 MB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-synapse==2.1.0b2\n",
      "  Downloading azure_mgmt_synapse-2.1.0b2-py2.py3-none-any.whl (546 kB)\n",
      "     |████████████████████████████████| 546 kB 42.1 MB/s            \n",
      "\u001b[?25hCollecting azure-keyvault~=1.1.0\n",
      "  Using cached azure_keyvault-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Collecting azure-mgmt-media~=9.0\n",
      "  Downloading azure_mgmt_media-9.0.0-py3-none-any.whl (211 kB)\n",
      "     |████████████████████████████████| 211 kB 57.0 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-datalake-analytics~=0.2.1\n",
      "  Downloading azure_mgmt_datalake_analytics-0.2.1-py2.py3-none-any.whl (146 kB)\n",
      "     |████████████████████████████████| 146 kB 64.1 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-servicebus~=7.1.0\n",
      "  Downloading azure_mgmt_servicebus-7.1.0-py2.py3-none-any.whl (539 kB)\n",
      "     |████████████████████████████████| 539 kB 52.8 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-consumption~=2.0\n",
      "  Using cached azure_mgmt_consumption-2.0.0-py2.py3-none-any.whl (46 kB)\n",
      "Collecting websocket-client~=1.3.1\n",
      "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
      "     |████████████████████████████████| 54 kB 6.6 MB/s             \n",
      "\u001b[?25hCollecting PyGithub~=1.38\n",
      "  Downloading PyGithub-1.55-py3-none-any.whl (291 kB)\n",
      "     |████████████████████████████████| 291 kB 33.2 MB/s            \n",
      "\u001b[?25hCollecting azure-datalake-store~=0.0.49\n",
      "  Using cached azure_datalake_store-0.0.52-py2.py3-none-any.whl (61 kB)\n",
      "Collecting azure-mgmt-recoveryservicesbackup~=4.1.1\n",
      "  Downloading azure_mgmt_recoveryservicesbackup-4.1.1-py3-none-any.whl (474 kB)\n",
      "     |████████████████████████████████| 474 kB 46.1 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-containerregistry==8.2.0\n",
      "  Downloading azure_mgmt_containerregistry-8.2.0-py2.py3-none-any.whl (928 kB)\n",
      "     |████████████████████████████████| 928 kB 54.6 MB/s            \n",
      "\u001b[?25hCollecting xmltodict~=0.12\n",
      "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Collecting azure-mgmt-authorization~=0.61.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "     |████████████████████████████████| 94 kB 1.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-netapp~=7.0.0\n",
      "  Downloading azure_mgmt_netapp-7.0.0-py3-none-any.whl (141 kB)\n",
      "     |████████████████████████████████| 141 kB 44.4 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-iotcentral~=9.0.0\n",
      "  Downloading azure_mgmt_iotcentral-9.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting azure-mgmt-datamigration~=10.0.0\n",
      "  Downloading azure_mgmt_datamigration-10.0.0-py2.py3-none-any.whl (174 kB)\n",
      "     |████████████████████████████████| 174 kB 50.7 MB/s            \n",
      "\u001b[?25hCollecting azure-appconfiguration~=1.1.1\n",
      "  Downloading azure_appconfiguration-1.1.1-py2.py3-none-any.whl (37 kB)\n",
      "Collecting azure-mgmt-cognitiveservices~=13.1.0\n",
      "  Downloading azure_mgmt_cognitiveservices-13.1.0-py3-none-any.whl (95 kB)\n",
      "     |████████████████████████████████| 95 kB 3.7 MB/s             \n",
      "\u001b[?25hCollecting azure-synapse-spark\n",
      "  Downloading azure_synapse_spark-0.2.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting azure-mgmt-managedservices~=1.0\n",
      "  Downloading azure_mgmt_managedservices-1.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-mgmt-appconfiguration==2.1.0b2\n",
      "  Downloading azure_mgmt_appconfiguration-2.1.0b2-py3-none-any.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 968 kB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-marketplaceordering==1.1.0\n",
      "  Downloading azure_mgmt_marketplaceordering-1.1.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting azure-mgmt-hdinsight~=9.0.0\n",
      "  Downloading azure_mgmt_hdinsight-9.0.0-py2.py3-none-any.whl (125 kB)\n",
      "     |████████████████████████████████| 125 kB 6.5 MB/s            \n",
      "\u001b[?25hCollecting fabric~=2.4\n",
      "  Downloading fabric-2.7.0-py2.py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 6.6 MB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-batchai==7.0.0b1\n",
      "  Downloading azure_mgmt_batchai-7.0.0b1-py2.py3-none-any.whl (99 kB)\n",
      "     |████████████████████████████████| 99 kB 2.8 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-recoveryservices~=2.0.0\n",
      "  Downloading azure_mgmt_recoveryservices-2.0.0-py2.py3-none-any.whl (79 kB)\n",
      "     |████████████████████████████████| 79 kB 16.4 MB/s            \n",
      "\u001b[?25hCollecting azure-keyvault-administration==4.0.0b3\n",
      "  Downloading azure_keyvault_administration-4.0.0b3-py2.py3-none-any.whl (77 kB)\n",
      "     |████████████████████████████████| 77 kB 10.2 MB/s            \n",
      "\u001b[?25hCollecting azure-synapse-managedprivateendpoints~=0.3.0\n",
      "  Downloading azure_synapse_managedprivateendpoints-0.3.0-py2.py3-none-any.whl (19 kB)\n",
      "Collecting azure-mgmt-reservations==0.6.0\n",
      "  Downloading azure_mgmt_reservations-0.6.0-py2.py3-none-any.whl (33 kB)\n",
      "Collecting azure-mgmt-servicefabric~=1.0.0\n",
      "  Downloading azure_mgmt_servicefabric-1.0.0-py2.py3-none-any.whl (139 kB)\n",
      "     |████████████████████████████████| 139 kB 40.5 MB/s            \n",
      "\u001b[?25hCollecting colorama~=0.4.4\n",
      "  Using cached colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting azure-mgmt-network~=19.3.0\n",
      "  Downloading azure_mgmt_network-19.3.0-py2.py3-none-any.whl (21.1 MB)\n",
      "     |████████████████████████████████| 21.1 MB 34.9 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-containerinstance~=9.1.0\n",
      "  Downloading azure_mgmt_containerinstance-9.1.0-py2.py3-none-any.whl (58 kB)\n",
      "     |████████████████████████████████| 58 kB 13.5 MB/s            \n",
      "\u001b[?25hCollecting chardet~=3.0.4\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "     |████████████████████████████████| 133 kB 63.3 MB/s            \n",
      "\u001b[?25hCollecting javaproperties~=0.5.1\n",
      "  Downloading javaproperties-0.5.2-py2.py3-none-any.whl (19 kB)\n",
      "Collecting scp~=0.13.2\n",
      "  Downloading scp-0.13.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: urllib3[secure] in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli) (1.26.9)\n",
      "Collecting azure-synapse-accesscontrol~=0.5.0\n",
      "  Downloading azure_synapse_accesscontrol-0.5.0-py2.py3-none-any.whl (30 kB)\n",
      "Collecting azure-mgmt-web~=6.1.0\n",
      "  Downloading azure_mgmt_web-6.1.0-py3-none-any.whl (3.9 MB)\n",
      "     |████████████████████████████████| 3.9 MB 75.2 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-keyvault==9.3.0\n",
      "  Downloading azure_mgmt_keyvault-9.3.0-py2.py3-none-any.whl (412 kB)\n",
      "     |████████████████████████████████| 412 kB 35.5 MB/s            \n",
      "\u001b[?25hCollecting PyNaCl~=1.4.0\n",
      "  Downloading PyNaCl-1.4.0-cp35-abi3-macosx_10_10_x86_64.whl (380 kB)\n",
      "     |████████████████████████████████| 380 kB 36.6 MB/s            \n",
      "\u001b[?25hCollecting azure-batch~=12.0.0\n",
      "  Downloading azure_batch-12.0.0-py2.py3-none-any.whl (231 kB)\n",
      "     |████████████████████████████████| 231 kB 62.0 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-monitor~=3.0.0\n",
      "  Downloading azure_mgmt_monitor-3.0.0-py2.py3-none-any.whl (839 kB)\n",
      "     |████████████████████████████████| 839 kB 46.9 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-security==2.0.0b1\n",
      "  Downloading azure_mgmt_security-2.0.0b1-py2.py3-none-any.whl (344 kB)\n",
      "     |████████████████████████████████| 344 kB 80.3 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-extendedlocation==1.0.0b2\n",
      "  Downloading azure_mgmt_extendedlocation-1.0.0b2-py2.py3-none-any.whl (37 kB)\n",
      "Collecting azure-mgmt-policyinsights~=1.0.0\n",
      "  Downloading azure_mgmt_policyinsights-1.0.0-py2.py3-none-any.whl (78 kB)\n",
      "     |████████████████████████████████| 78 kB 16.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-billing==6.0.0\n",
      "  Downloading azure_mgmt_billing-6.0.0-py2.py3-none-any.whl (166 kB)\n",
      "     |████████████████████████████████| 166 kB 19.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-containerservice~=19.0.0\n",
      "  Downloading azure_mgmt_containerservice-19.0.0-py3-none-any.whl (2.7 MB)\n",
      "     |████████████████████████████████| 2.7 MB 45.2 MB/s            \n",
      "\u001b[?25hCollecting azure-loganalytics~=0.1.0\n",
      "  Using cached azure_loganalytics-0.1.1-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: packaging<22.0,>=20.9 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli) (21.3)\n",
      "Collecting azure-data-tables==12.2.0\n",
      "  Downloading azure_data_tables-12.2.0-py2.py3-none-any.whl (108 kB)\n",
      "     |████████████████████████████████| 108 kB 19.0 MB/s            \n",
      "\u001b[?25hCollecting antlr4-python3-runtime~=4.7.2\n",
      "  Downloading antlr4-python3-runtime-4.7.2.tar.gz (112 kB)\n",
      "     |████████████████████████████████| 112 kB 38.9 MB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting azure-mgmt-sqlvirtualmachine==1.0.0b2\n",
      "  Downloading azure_mgmt_sqlvirtualmachine-1.0.0b2-py3-none-any.whl (57 kB)\n",
      "     |████████████████████████████████| 57 kB 8.7 MB/s             \n",
      "\u001b[?25hCollecting azure-keyvault-keys==4.5.1\n",
      "  Downloading azure_keyvault_keys-4.5.1-py3-none-any.whl (375 kB)\n",
      "     |████████████████████████████████| 375 kB 33.4 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-servicefabricmanagedclusters~=1.0.0\n",
      "  Downloading azure_mgmt_servicefabricmanagedclusters-1.0.0-py2.py3-none-any.whl (112 kB)\n",
      "     |████████████████████████████████| 112 kB 41.8 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-kusto~=0.3.0\n",
      "  Downloading azure_mgmt_kusto-0.3.0-py2.py3-none-any.whl (73 kB)\n",
      "     |████████████████████████████████| 73 kB 5.2 MB/s             \n",
      "\u001b[?25hCollecting azure-synapse-artifacts~=0.12.0\n",
      "  Downloading azure_synapse_artifacts-0.12.0-py3-none-any.whl (421 kB)\n",
      "     |████████████████████████████████| 421 kB 12.1 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-eventhub~=9.1.0\n",
      "  Downloading azure_mgmt_eventhub-9.1.0-py2.py3-none-any.whl (383 kB)\n",
      "     |████████████████████████████████| 383 kB 41.0 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-batch~=16.1.0\n",
      "  Downloading azure_mgmt_batch-16.1.0-py3-none-any.whl (122 kB)\n",
      "     |████████████████████████████████| 122 kB 35.8 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-maps~=2.0.0\n",
      "  Downloading azure_mgmt_maps-2.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-mgmt-imagebuilder~=1.0.0\n",
      "  Downloading azure_mgmt_imagebuilder-1.0.0-py2.py3-none-any.whl (45 kB)\n",
      "     |████████████████████████████████| 45 kB 9.5 MB/s             \n",
      "\u001b[?25hCollecting azure-graphrbac~=0.60.0\n",
      "  Downloading azure_graphrbac-0.60.0-py2.py3-none-any.whl (139 kB)\n",
      "     |████████████████████████████████| 139 kB 19.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-redis~=13.1.0\n",
      "  Downloading azure_mgmt_redis-13.1.0-py2.py3-none-any.whl (87 kB)\n",
      "     |████████████████████████████████| 87 kB 14.6 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-cosmosdb==7.0.0b2\n",
      "  Downloading azure_mgmt_cosmosdb-7.0.0b2-py2.py3-none-any.whl (319 kB)\n",
      "     |████████████████████████████████| 319 kB 56.4 MB/s            \n",
      "\u001b[?25hCollecting azure-cosmos>=3.0.2,~=3.0\n",
      "  Downloading azure_cosmos-3.2.0-py2.py3-none-any.whl (106 kB)\n",
      "     |████████████████████████████████| 106 kB 45.1 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-botservice~=0.3.0\n",
      "  Downloading azure_mgmt_botservice-0.3.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting azure-mgmt-privatedns~=1.0.0\n",
      "  Downloading azure_mgmt_privatedns-1.0.0-py2.py3-none-any.whl (43 kB)\n",
      "     |████████████████████████████████| 43 kB 5.2 MB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-loganalytics==13.0.0b4\n",
      "  Downloading azure_mgmt_loganalytics-13.0.0b4-py3-none-any.whl (162 kB)\n",
      "     |████████████████████████████████| 162 kB 29.4 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-signalr==1.0.0b2\n",
      "  Downloading azure_mgmt_signalr-1.0.0b2-py2.py3-none-any.whl (71 kB)\n",
      "     |████████████████████████████████| 71 kB 12.1 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-advisor==9.0.0\n",
      "  Downloading azure_mgmt_advisor-9.0.0-py2.py3-none-any.whl (46 kB)\n",
      "     |████████████████████████████████| 46 kB 7.4 MB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-search~=8.0\n",
      "  Downloading azure_mgmt_search-8.0.0-py2.py3-none-any.whl (71 kB)\n",
      "     |████████████████████████████████| 71 kB 18.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-dns~=8.0.0\n",
      "  Downloading azure_mgmt_dns-8.0.0-py2.py3-none-any.whl (118 kB)\n",
      "     |████████████████████████████████| 118 kB 47.7 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-sql==4.0.0b1\n",
      "  Downloading azure_mgmt_sql-4.0.0b1-py2.py3-none-any.whl (916 kB)\n",
      "     |████████████████████████████████| 916 kB 43.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-databoxedge~=1.0.0\n",
      "  Downloading azure_mgmt_databoxedge-1.0.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 46.7 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-applicationinsights~=1.0.0\n",
      "  Downloading azure_mgmt_applicationinsights-1.0.0-py2.py3-none-any.whl (302 kB)\n",
      "     |████████████████████████████████| 302 kB 58.4 MB/s            \n",
      "\u001b[?25hCollecting semver==2.13.0\n",
      "  Using cached semver-2.13.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-storage~=20.0.0\n",
      "  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\n",
      "     |████████████████████████████████| 2.0 MB 61.8 MB/s            \n",
      "\u001b[?25hCollecting sshtunnel~=0.1.4\n",
      "  Downloading sshtunnel-0.1.5-py2.py3-none-any.whl (23 kB)\n",
      "Collecting azure-mgmt-rdbms~=10.0.0\n",
      "  Downloading azure_mgmt_rdbms-10.0.0-py2.py3-none-any.whl (644 kB)\n",
      "     |████████████████████████████████| 644 kB 18.7 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-relay~=0.1.0\n",
      "  Using cached azure_mgmt_relay-0.1.0-py2.py3-none-any.whl (36 kB)\n",
      "Collecting azure-mgmt-redhatopenshift==1.0.0\n",
      "  Downloading azure_mgmt_redhatopenshift-1.0.0-py2.py3-none-any.whl (41 kB)\n",
      "     |████████████████████████████████| 41 kB 141 kB/s             \n",
      "\u001b[?25hCollecting jsondiff~=1.3.0\n",
      "  Downloading jsondiff-1.3.1.tar.gz (6.5 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting azure-mgmt-resource==20.0.0\n",
      "  Downloading azure_mgmt_resource-20.0.0-py2.py3-none-any.whl (2.3 MB)\n",
      "     |████████████████████████████████| 2.3 MB 36.2 MB/s            \n",
      "\u001b[?25hCollecting azure-cli-core==2.36.0\n",
      "  Downloading azure_cli_core-2.36.0-py3-none-any.whl (180 kB)\n",
      "     |████████████████████████████████| 180 kB 70.0 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-msi~=6.0.0\n",
      "  Downloading azure_mgmt_msi-6.0.1-py3-none-any.whl (73 kB)\n",
      "     |████████████████████████████████| 73 kB 4.7 MB/s             \n",
      "\u001b[?25hCollecting azure-mgmt-servicelinker==1.0.0b2\n",
      "  Downloading azure_mgmt_servicelinker-1.0.0b2-py3-none-any.whl (32 kB)\n",
      "Collecting azure-mgmt-devtestlabs~=4.0\n",
      "  Downloading azure_mgmt_devtestlabs-4.0.0-py2.py3-none-any.whl (137 kB)\n",
      "     |████████████████████████████████| 137 kB 40.8 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-apimanagement~=3.0.0\n",
      "  Downloading azure_mgmt_apimanagement-3.0.0-py3-none-any.whl (588 kB)\n",
      "     |████████████████████████████████| 588 kB 32.4 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-eventgrid==9.0.0\n",
      "  Downloading azure_mgmt_eventgrid-9.0.0-py2.py3-none-any.whl (178 kB)\n",
      "     |████████████████████████████████| 178 kB 51.7 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-iothub==2.2.0\n",
      "  Downloading azure_mgmt_iothub-2.2.0-py3-none-any.whl (839 kB)\n",
      "     |████████████████████████████████| 839 kB 48.6 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-cdn==12.0.0\n",
      "  Downloading azure_mgmt_cdn-12.0.0-py3-none-any.whl (239 kB)\n",
      "     |████████████████████████████████| 239 kB 19.5 MB/s            \n",
      "\u001b[?25hCollecting azure-mgmt-datalake-store~=0.5.0\n",
      "  Using cached azure_mgmt_datalake_store-0.5.0-py2.py3-none-any.whl (88 kB)\n",
      "Collecting humanfriendly~=10.0\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "     |████████████████████████████████| 86 kB 17.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: msal<2.0.0,>=1.17.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli-core==2.36.0->azure-cli) (1.17.0)\n",
      "Collecting knack~=0.9.0\n",
      "  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n",
      "     |████████████████████████████████| 59 kB 19.9 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: msal-extensions~=1.0.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli-core==2.36.0->azure-cli) (1.0.0)\n",
      "Collecting pyopenssl>=17.1.0\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 12.1 MB/s            \n",
      "\u001b[?25hCollecting azure-cli-telemetry==1.0.6.*\n",
      "  Downloading azure_cli_telemetry-1.0.6-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cryptography in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli-core==2.36.0->azure-cli) (37.0.2)\n",
      "Collecting paramiko<3.0.0,>=2.0.8\n",
      "  Downloading paramiko-2.10.4-py2.py3-none-any.whl (212 kB)\n",
      "     |████████████████████████████████| 212 kB 48.3 MB/s            \n",
      "\u001b[?25hCollecting pkginfo>=1.5.0.1\n",
      "  Using cached pkginfo-1.8.2-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: PyJWT>=2.1.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli-core==2.36.0->azure-cli) (2.3.0)\n",
      "Collecting argcomplete~=1.8\n",
      "  Downloading argcomplete-1.12.3-py2.py3-none-any.whl (38 kB)\n",
      "Collecting azure-mgmt-core<2,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.3.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting msrestazure~=0.6.4\n",
      "  Using cached msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: psutil~=5.9 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-cli-core==2.36.0->azure-cli) (5.9.0)\n",
      "Collecting jmespath\n",
      "  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: msrest>=0.6.21 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-data-tables==12.2.0->azure-cli) (0.6.21)\n",
      "Requirement already satisfied: azure-common~=1.1 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-keyvault-administration==4.0.0b3->azure-cli) (1.1.28)\n",
      "Collecting applicationinsights<0.12,>=0.11.1\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "     |████████████████████████████████| 55 kB 10.1 MB/s            \n",
      "\u001b[?25hCollecting portalocker~=1.2\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from pandavro) (1.22.3)\n",
      "Requirement already satisfied: fastavro>=0.14.11 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from pandavro) (1.4.11)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from scikit-learn) (1.8.0)\n",
      "Requirement already satisfied: cffi in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-datalake-store~=0.0.49->azure-cli) (1.15.0)\n",
      "Collecting adal>=0.4.2\n",
      "  Using cached adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azure-nspkg>=2.0.0\n",
      "  Using cached azure_nspkg-3.0.2-py3-none-any.whl (1.5 kB)\n",
      "Collecting azure-mgmt-nspkg>=2.0.0\n",
      "  Using cached azure_mgmt_nspkg-3.0.2-py3-none-any.whl (1.6 kB)\n",
      "Collecting azure-mgmt-datalake-nspkg>=2.0.0\n",
      "  Using cached azure_mgmt_datalake_nspkg-3.0.1-py3-none-any.whl (1.7 kB)\n",
      "Requirement already satisfied: python-dateutil in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-multiapi-storage~=0.8.0->azure-cli) (2.8.2)\n",
      "Requirement already satisfied: azure-storage-blob<13.0.0,>=12.10.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from azure-storage-file-datalake>=12.5.0->feathr) (12.11.0)\n",
      "Collecting pathlib2\n",
      "  Downloading pathlib2-2.3.7.post1-py2.py3-none-any.whl (18 kB)\n",
      "Collecting invoke<2.0,>=1.3\n",
      "  Downloading invoke-1.7.0-py3-none-any.whl (171 kB)\n",
      "     |████████████████████████████████| 171 kB 6.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google>=3.0.0->feathr) (4.11.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-python-client>=2.41.0->feathr) (2.7.3)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-python-client>=2.41.0->feathr) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-python-client>=2.41.0->feathr) (4.1.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-python-client>=2.41.0->feathr) (0.20.4)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-python-client>=2.41.0->feathr) (2.6.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from packaging<22.0,>=20.9->azure-cli) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from pandas->feathr) (2022.1)\n",
      "Requirement already satisfied: deprecated in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from PyGithub~=1.38->azure-cli) (1.2.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from requests->feathr) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from requests->feathr) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from requests->feathr) (2.0.12)\n",
      "Requirement already satisfied: oauthlib>=3.1.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from databricks-cli->feathr) (3.2.0)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from databricks-cli->feathr) (0.8.9)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from Jinja2->feathr) (2.1.1)\n",
      "Requirement already satisfied: openpyxl>=3.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from pyapacheatlas->feathr) (3.0.9)\n",
      "Requirement already satisfied: async-timeout>=4.0.2 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from redis->feathr) (4.0.2)\n",
      "Requirement already satisfied: pycparser in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from cffi->azure-datalake-store~=0.0.49->azure-cli) (2.21)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from deprecated->PyGithub~=1.38->azure-cli) (1.14.1)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=2.41.0->feathr) (3.20.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=2.41.0->feathr) (1.56.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (5.0.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (0.2.8)\n",
      "Requirement already satisfied: pygments in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from knack~=0.9.0->azure-cli-core==2.36.0->azure-cli) (2.12.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from msrest>=0.6.21->azure-data-tables==12.2.0->azure-cli) (1.3.1)\n",
      "Requirement already satisfied: isodate>=0.6.0 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from msrest>=0.6.21->azure-data-tables==12.2.0->azure-cli) (0.6.1)\n",
      "Requirement already satisfied: et-xmlfile in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from openpyxl>=3.0->pyapacheatlas->feathr) (1.1.0)\n",
      "Collecting bcrypt>=3.1.3\n",
      "  Downloading bcrypt-3.2.2-cp36-abi3-macosx_10_10_universal2.whl (50 kB)\n",
      "     |████████████████████████████████| 50 kB 20.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from beautifulsoup4->google>=3.0.0->feathr) (2.3.2.post1)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=2.41.0->feathr) (0.4.8)\n",
      "Using legacy 'setup.py install' for antlr4-python3-runtime, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for jsondiff, since package 'wheel' is not installed.\n",
      "Installing collected packages: azure-nspkg, PySocks, PyNaCl, portalocker, jmespath, bcrypt, azure-mgmt-nspkg, argcomplete, applicationinsights, adal, pyopenssl, pkginfo, pathlib2, paramiko, msrestazure, knack, invoke, humanfriendly, azure-mgmt-datalake-nspkg, azure-mgmt-core, azure-cli-telemetry, xmltodict, websocket-client, sshtunnel, semver, scp, PyGithub, jsondiff, joblib, javaproperties, fabric, colorama, chardet, azure-synapse-spark, azure-synapse-managedprivateendpoints, azure-synapse-artifacts, azure-synapse-accesscontrol, azure-storage-common, azure-multiapi-storage, azure-mgmt-web, azure-mgmt-trafficmanager, azure-mgmt-synapse, azure-mgmt-storage, azure-mgmt-sqlvirtualmachine, azure-mgmt-sql, azure-mgmt-signalr, azure-mgmt-servicelinker, azure-mgmt-servicefabricmanagedclusters, azure-mgmt-servicefabric, azure-mgmt-servicebus, azure-mgmt-security, azure-mgmt-search, azure-mgmt-resource, azure-mgmt-reservations, azure-mgmt-relay, azure-mgmt-redis, azure-mgmt-redhatopenshift, azure-mgmt-recoveryservicesbackup, azure-mgmt-recoveryservices, azure-mgmt-rdbms, azure-mgmt-privatedns, azure-mgmt-policyinsights, azure-mgmt-network, azure-mgmt-netapp, azure-mgmt-msi, azure-mgmt-monitor, azure-mgmt-media, azure-mgmt-marketplaceordering, azure-mgmt-maps, azure-mgmt-managementgroups, azure-mgmt-managedservices, azure-mgmt-loganalytics, azure-mgmt-kusto, azure-mgmt-keyvault, azure-mgmt-iothubprovisioningservices, azure-mgmt-iothub, azure-mgmt-iotcentral, azure-mgmt-imagebuilder, azure-mgmt-hdinsight, azure-mgmt-extendedlocation, azure-mgmt-eventhub, azure-mgmt-eventgrid, azure-mgmt-dns, azure-mgmt-devtestlabs, azure-mgmt-deploymentmanager, azure-mgmt-datamigration, azure-mgmt-datalake-store, azure-mgmt-datalake-analytics, azure-mgmt-databoxedge, azure-mgmt-cosmosdb, azure-mgmt-containerservice, azure-mgmt-containerregistry, azure-mgmt-containerinstance, azure-mgmt-consumption, azure-mgmt-compute, azure-mgmt-cognitiveservices, azure-mgmt-cdn, azure-mgmt-botservice, azure-mgmt-billing, azure-mgmt-batchai, azure-mgmt-batch, azure-mgmt-authorization, azure-mgmt-applicationinsights, azure-mgmt-appconfiguration, azure-mgmt-apimanagement, azure-mgmt-advisor, azure-loganalytics, azure-keyvault-keys, azure-keyvault-administration, azure-keyvault, azure-graphrbac, azure-datalake-store, azure-data-tables, azure-cosmos, azure-cli-core, azure-batch, azure-appconfiguration, antlr4-python3-runtime, scikit-learn, azure-cli\n",
      "  Attempting uninstall: portalocker\n",
      "    Found existing installation: portalocker 2.4.0\n",
      "    Uninstalling portalocker-2.4.0:\n",
      "      Successfully uninstalled portalocker-2.4.0\n",
      "    Running setup.py install for jsondiff ... \u001b[?25ldone\n",
      "\u001b[?25h  Attempting uninstall: azure-synapse-spark\n",
      "    Found existing installation: azure-synapse-spark 0.7.0\n",
      "    Uninstalling azure-synapse-spark-0.7.0:\n",
      "      Successfully uninstalled azure-synapse-spark-0.7.0\n",
      "    Running setup.py install for antlr4-python3-runtime ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyGithub-1.55 PyNaCl-1.4.0 PySocks-1.7.1 adal-1.2.7 antlr4-python3-runtime-4.7.2 applicationinsights-0.11.10 argcomplete-1.12.3 azure-appconfiguration-1.1.1 azure-batch-12.0.0 azure-cli-2.36.0 azure-cli-core-2.36.0 azure-cli-telemetry-1.0.6 azure-cosmos-3.2.0 azure-data-tables-12.2.0 azure-datalake-store-0.0.52 azure-graphrbac-0.60.0 azure-keyvault-1.1.0 azure-keyvault-administration-4.0.0b3 azure-keyvault-keys-4.5.1 azure-loganalytics-0.1.1 azure-mgmt-advisor-9.0.0 azure-mgmt-apimanagement-3.0.0 azure-mgmt-appconfiguration-2.1.0b2 azure-mgmt-applicationinsights-1.0.0 azure-mgmt-authorization-0.61.0 azure-mgmt-batch-16.1.0 azure-mgmt-batchai-7.0.0b1 azure-mgmt-billing-6.0.0 azure-mgmt-botservice-0.3.0 azure-mgmt-cdn-12.0.0 azure-mgmt-cognitiveservices-13.1.0 azure-mgmt-compute-26.1.0 azure-mgmt-consumption-2.0.0 azure-mgmt-containerinstance-9.1.0 azure-mgmt-containerregistry-8.2.0 azure-mgmt-containerservice-19.0.0 azure-mgmt-core-1.3.0 azure-mgmt-cosmosdb-7.0.0b2 azure-mgmt-databoxedge-1.0.0 azure-mgmt-datalake-analytics-0.2.1 azure-mgmt-datalake-nspkg-3.0.1 azure-mgmt-datalake-store-0.5.0 azure-mgmt-datamigration-10.0.0 azure-mgmt-deploymentmanager-0.2.0 azure-mgmt-devtestlabs-4.0.0 azure-mgmt-dns-8.0.0 azure-mgmt-eventgrid-9.0.0 azure-mgmt-eventhub-9.1.0 azure-mgmt-extendedlocation-1.0.0b2 azure-mgmt-hdinsight-9.0.0 azure-mgmt-imagebuilder-1.0.0 azure-mgmt-iotcentral-9.0.0 azure-mgmt-iothub-2.2.0 azure-mgmt-iothubprovisioningservices-1.1.0 azure-mgmt-keyvault-9.3.0 azure-mgmt-kusto-0.3.0 azure-mgmt-loganalytics-13.0.0b4 azure-mgmt-managedservices-1.0.0 azure-mgmt-managementgroups-1.0.0 azure-mgmt-maps-2.0.0 azure-mgmt-marketplaceordering-1.1.0 azure-mgmt-media-9.0.0 azure-mgmt-monitor-3.0.0 azure-mgmt-msi-6.0.1 azure-mgmt-netapp-7.0.0 azure-mgmt-network-19.3.0 azure-mgmt-nspkg-3.0.2 azure-mgmt-policyinsights-1.0.0 azure-mgmt-privatedns-1.0.0 azure-mgmt-rdbms-10.0.0 azure-mgmt-recoveryservices-2.0.0 azure-mgmt-recoveryservicesbackup-4.1.1 azure-mgmt-redhatopenshift-1.0.0 azure-mgmt-redis-13.1.0 azure-mgmt-relay-0.1.0 azure-mgmt-reservations-0.6.0 azure-mgmt-resource-20.0.0 azure-mgmt-search-8.0.0 azure-mgmt-security-2.0.0b1 azure-mgmt-servicebus-7.1.0 azure-mgmt-servicefabric-1.0.0 azure-mgmt-servicefabricmanagedclusters-1.0.0 azure-mgmt-servicelinker-1.0.0b2 azure-mgmt-signalr-1.0.0b2 azure-mgmt-sql-4.0.0b1 azure-mgmt-sqlvirtualmachine-1.0.0b2 azure-mgmt-storage-20.0.0 azure-mgmt-synapse-2.1.0b2 azure-mgmt-trafficmanager-1.0.0 azure-mgmt-web-6.1.0 azure-multiapi-storage-0.8.0 azure-nspkg-3.0.2 azure-storage-common-1.4.2 azure-synapse-accesscontrol-0.5.0 azure-synapse-artifacts-0.12.0 azure-synapse-managedprivateendpoints-0.3.0 azure-synapse-spark-0.2.0 bcrypt-3.2.2 chardet-3.0.4 colorama-0.4.4 fabric-2.7.0 humanfriendly-10.0 invoke-1.7.0 javaproperties-0.5.2 jmespath-1.0.0 joblib-1.1.0 jsondiff-1.3.1 knack-0.9.0 msrestazure-0.6.4 paramiko-2.10.4 pathlib2-2.3.7.post1 pkginfo-1.8.2 portalocker-1.7.1 pyopenssl-22.0.0 scikit-learn-1.0.2 scp-0.13.6 semver-2.13.0 sshtunnel-0.1.5 websocket-client-1.3.2 xmltodict-0.13.0\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/Users/hnlin/IdeaProjects/feathr_sample/sample_feathr/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install feathr azure-cli  pandavro scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to Azure with a device code (You will see instructions in the output):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! az login --use-device-code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tempfile\n",
    "from datetime import datetime, timedelta\n",
    "from math import sqrt\n",
    "\n",
    "import pandas as pd\n",
    "import pandavro as pdx\n",
    "from feathr import FeathrClient\n",
    "from feathr import BOOLEAN, FLOAT, INT32, ValueType\n",
    "from feathr import Feature, DerivedFeature, FeatureAnchor\n",
    "from feathr import BackfillTime, MaterializationSettings\n",
    "from feathr import FeatureQuery, ObservationSettings\n",
    "from feathr import RedisSink\n",
    "from feathr import INPUT_CONTEXT, HdfsSource\n",
    "from feathr import WindowAggTransformation\n",
    "from feathr import TypedKey\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.keyvault.secrets import SecretClient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the required credentials from Azure KeyVault"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the required credentials from Azure Key Vault\n",
    "key_vault_name=resource_prefix+\"kv\"\n",
    "synapse_workspace_url=resource_prefix+\"syws\"\n",
    "adls_account=resource_prefix+\"dls\"\n",
    "adls_fs_name=resource_prefix+\"fs\"\n",
    "purview_name=resource_prefix+\"purview\"\n",
    "key_vault_uri = f\"https://{key_vault_name}.vault.azure.net\"\n",
    "credential = DefaultAzureCredential(exclude_interactive_browser_credential=False)\n",
    "client = SecretClient(vault_url=key_vault_uri, credential=credential)\n",
    "secretName = \"FEATHR-ONLINE-STORE-CONN\"\n",
    "retrieved_secret = client.get_secret(secretName).value\n",
    "\n",
    "# Get redis credentials; This is to parse Redis connection string.\n",
    "redis_port=retrieved_secret.split(',')[0].split(\":\")[1]\n",
    "redis_host=retrieved_secret.split(',')[0].split(\":\")[0]\n",
    "redis_password=retrieved_secret.split(',')[1].split(\"password=\",1)[1]\n",
    "redis_ssl=retrieved_secret.split(',')[2].split(\"ssl=\",1)[1]\n",
    "\n",
    "# Set the resource link\n",
    "os.environ['spark_config__azure_synapse__dev_url'] = f'https://{synapse_workspace_url}.dev.azuresynapse.net'\n",
    "os.environ['spark_config__azure_synapse__pool_name'] = 'spark31'\n",
    "os.environ['spark_config__azure_synapse__workspace_dir'] = f'abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/feathr_project'\n",
    "os.environ['feature_registry__purview__purview_name'] = f'{purview_name}'\n",
    "os.environ['online_store__redis__host'] = redis_host\n",
    "os.environ['online_store__redis__port'] = redis_port\n",
    "os.environ['online_store__redis__ssl_enabled'] = redis_ssl\n",
    "os.environ['REDIS_PASSWORD']=redis_password\n",
    "os.environ['feature_registry__purview__purview_name'] = f'{purview_name}'\n",
    "feathr_output_path = f'abfss://{adls_fs_name}@{adls_account}.dfs.core.windows.net/feathr_output'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite: Configure the required environment (Don't need to update if using the above Quick Start Template)\n",
    "\n",
    "In the first step (Provision cloud resources), you should have provisioned all the required cloud resources. If you use Feathr CLI to create a workspace, you should have a folder with a file called `feathr_config.yaml` in it with all the required configurations. Otherwise, update the configuration below.\n",
    "\n",
    "The code below will write this configuration string to a temporary location and load it to Feathr. Please still refer to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It should also have more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "yaml_config = \"\"\"\n",
    "# Please refer to https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml for explanations on the meaning of each field.\n",
    "api_version: 1\n",
    "project_config:\n",
    "  project_name: 'feathr_getting_started'\n",
    "  required_environment_variables:\n",
    "    - 'REDIS_PASSWORD'\n",
    "    - 'AZURE_CLIENT_ID'\n",
    "    - 'AZURE_TENANT_ID'\n",
    "    - 'AZURE_CLIENT_SECRET'\n",
    "offline_store:\n",
    "  adls:\n",
    "    adls_enabled: true\n",
    "  wasb:\n",
    "    wasb_enabled: true\n",
    "  s3:\n",
    "    s3_enabled: false\n",
    "    s3_endpoint: 's3.amazonaws.com'\n",
    "  jdbc:\n",
    "    jdbc_enabled: false\n",
    "    jdbc_database: 'feathrtestdb'\n",
    "    jdbc_table: 'feathrtesttable'\n",
    "  snowflake:\n",
    "    url: \"dqllago-ol19457.snowflakecomputing.com\"\n",
    "    user: \"feathrintegration\"\n",
    "    role: \"ACCOUNTADMIN\"\n",
    "spark_config:\n",
    "  spark_cluster: 'azure_synapse'\n",
    "  spark_result_output_parts: '1'\n",
    "  azure_synapse:\n",
    "    dev_url: 'https://feathrazuretest3synapse.dev.azuresynapse.net'\n",
    "    pool_name: 'spark3'\n",
    "    workspace_dir: 'abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started'\n",
    "    executor_size: 'Small'\n",
    "    executor_num: 4\n",
    "    feathr_runtime_location: wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar\n",
    "  databricks:\n",
    "    workspace_instance_url: 'https://adb-2474129336842816.16.azuredatabricks.net'\n",
    "    config_template: {'run_name':'','new_cluster':{'spark_version':'9.1.x-scala2.12','node_type_id':'Standard_D3_v2','num_workers':2,'spark_conf':{}},'libraries':[{'jar':''}],'spark_jar_task':{'main_class_name':'','parameters':['']}}\n",
    "    work_dir: 'dbfs:/feathr_getting_started'\n",
    "    feathr_runtime_location: https://azurefeathrstorage.blob.core.windows.net/public/feathr-assembly-LATEST.jar\n",
    "online_store:\n",
    "  redis:\n",
    "    host: 'feathrazuretest3redis.redis.cache.windows.net'\n",
    "    port: 6380\n",
    "    ssl_enabled: True\n",
    "feature_registry:\n",
    "  purview:\n",
    "    type_system_initialization: true\n",
    "    purview_name: 'feathrazuretest3-purview1'\n",
    "    delimiter: '__'\n",
    "\"\"\"\n",
    "tmp = tempfile.NamedTemporaryFile(mode='w', delete=False)\n",
    "with open(tmp.name, \"w\") as text_file:\n",
    "    text_file.write(yaml_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup necessary environment variables (Skip if using the above Quick Start Template)\n",
    "\n",
    "You should setup the environment variables in order to run this sample. More environment variables can be set by referring to [feathr_config.yaml](https://github.com/linkedin/feathr/blob/main/feathr_project/feathrcli/data/feathr_user_workspace/feathr_config.yaml) and use that as the source of truth. It also has more explanations on the meaning of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Feathr Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FeathrClient(config_path=tmp.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the data\n",
    "\n",
    "In this tutorial, we use Feathr Feature Store to create a model that predicts NYC Taxi total fare amount(original fare + tip + congestion surcharge). We have an observation data table, a raw source data table(tripdata_raw_source_data.csv) about the detailed trip information, and another raw source data about location(new_york_location_statistics_data.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripID</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>total_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1.01</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-01-01 11:25:59</td>\n",
       "      <td>2021-01-01 11:34:44</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>2.53</td>\n",
       "      <td>16.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1.12</td>\n",
       "      <td>8.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 23:04:56</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1.99</td>\n",
       "      <td>9.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2021-01-01 17:16:36</td>\n",
       "      <td>2021-01-01 17:16:40</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-52.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>0.00</td>\n",
       "      <td>52.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>2021-01-01 05:19:14</td>\n",
       "      <td>2021-01-01 00:19:21</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>0.00</td>\n",
       "      <td>216.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>2021-01-01 00:26:31</td>\n",
       "      <td>2021-01-01 00:28:50</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>5.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:57:46</td>\n",
       "      <td>2021-01-01 00:57:57</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>2021-01-01 00:58:32</td>\n",
       "      <td>2021-01-01 01:32:34</td>\n",
       "      <td>225</td>\n",
       "      <td>265</td>\n",
       "      <td>12.19</td>\n",
       "      <td>42.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 18:39:57</td>\n",
       "      <td>2021-01-01 18:55:25</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>5.48</td>\n",
       "      <td>19.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-01-01 00:51:27</td>\n",
       "      <td>2021-01-01 00:57:20</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>0.90</td>\n",
       "      <td>7.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-01-01 00:29:05</td>\n",
       "      <td>2021-01-01 00:29:07</td>\n",
       "      <td>42</td>\n",
       "      <td>264</td>\n",
       "      <td>0.09</td>\n",
       "      <td>12.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TripID  VendorID lpep_pickup_datetime lpep_dropoff_datetime  PULocationID  \\\n",
       "0        1         2  2021-01-01 00:15:56   2021-01-01 00:19:52            43   \n",
       "1        2        22  2021-01-01 11:25:59   2021-01-01 11:34:44           166   \n",
       "2        3        23  2021-01-01 00:45:57   2021-01-01 00:51:55            41   \n",
       "3        4        24  2020-12-31 23:57:51   2021-01-01 23:04:56           168   \n",
       "4        5        25  2021-01-01 17:16:36   2021-01-01 17:16:40           265   \n",
       "5        6        12  2021-01-01 00:16:36   2021-01-01 00:16:40           265   \n",
       "6        7        42  2021-01-01 05:19:14   2021-01-01 00:19:21           265   \n",
       "7        8        52  2021-01-01 00:26:31   2021-01-01 00:28:50            75   \n",
       "8        9         2  2021-01-01 00:57:46   2021-01-01 00:57:57           225   \n",
       "9       10        32  2021-01-01 00:58:32   2021-01-01 01:32:34           225   \n",
       "10      11         2  2021-01-01 18:39:57   2021-01-01 18:55:25            74   \n",
       "11      12        15  2021-01-01 00:51:27   2021-01-01 00:57:20            42   \n",
       "12      13        15  2021-01-01 00:29:05   2021-01-01 00:29:07            42   \n",
       "\n",
       "    DOLocationID  trip_distance  total_amount  \n",
       "0            151           1.01          6.80  \n",
       "1            239           2.53         16.86  \n",
       "2             42           1.12          8.30  \n",
       "3             75           1.99          9.30  \n",
       "4            265           0.00        -52.80  \n",
       "5            265           0.00         52.80  \n",
       "6            265           0.00        216.36  \n",
       "7             75           0.45          5.76  \n",
       "8            225           0.00          3.80  \n",
       "9            265          12.19         42.05  \n",
       "10            60           5.48         19.30  \n",
       "11            41           0.90          7.30  \n",
       "12           264           0.09         12.36  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "observation_pd = pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/taxi_trip_observation_data.csv\")\n",
    "observation_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TripID</th>\n",
       "      <th>VendorID</th>\n",
       "      <th>lpep_pickup_datetime</th>\n",
       "      <th>lpep_dropoff_datetime</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>...</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>2021-01-01 00:19:52</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>1.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>6.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>2021-01-01 11:25:59</td>\n",
       "      <td>2021-01-01 11:34:44</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>166</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>2.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.81</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>16.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>2021-01-01 00:51:55</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>2021-01-01 23:04:56</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>168</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.99</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>9.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>2021-01-01 17:16:36</td>\n",
       "      <td>2021-01-01 17:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-52.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>2021-01-01 00:16:40</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>52.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>2021-01-01 05:19:14</td>\n",
       "      <td>2021-01-01 00:19:21</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>265</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.06</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>216.36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>2021-01-01 00:26:31</td>\n",
       "      <td>2021-01-01 00:28:50</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.76</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 00:57:46</td>\n",
       "      <td>2021-01-01 00:57:57</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>2021-01-01 00:58:32</td>\n",
       "      <td>2021-01-01 01:32:34</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>225</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>12.19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.75</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>42.05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01 18:39:57</td>\n",
       "      <td>2021-01-01 18:55:25</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.30</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-01-01 00:51:27</td>\n",
       "      <td>2021-01-01 00:57:20</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>0.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>7.30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-01-01 00:29:05</td>\n",
       "      <td>2021-01-01 00:29:07</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>42</td>\n",
       "      <td>264</td>\n",
       "      <td>1</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.06</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.36</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    TripID  VendorID lpep_pickup_datetime lpep_dropoff_datetime  \\\n",
       "0        1         2  2021-01-01 00:15:56   2021-01-01 00:19:52   \n",
       "1        2        22  2021-01-01 11:25:59   2021-01-01 11:34:44   \n",
       "2        3        23  2021-01-01 00:45:57   2021-01-01 00:51:55   \n",
       "3        4        24  2020-12-31 23:57:51   2021-01-01 23:04:56   \n",
       "4        5        25  2021-01-01 17:16:36   2021-01-01 17:16:40   \n",
       "5        6        12  2021-01-01 00:16:36   2021-01-01 00:16:40   \n",
       "6        7        42  2021-01-01 05:19:14   2021-01-01 00:19:21   \n",
       "7        8        52  2021-01-01 00:26:31   2021-01-01 00:28:50   \n",
       "8        9         2  2021-01-01 00:57:46   2021-01-01 00:57:57   \n",
       "9       10        32  2021-01-01 00:58:32   2021-01-01 01:32:34   \n",
       "10      11         2  2021-01-01 18:39:57   2021-01-01 18:55:25   \n",
       "11      12        15  2021-01-01 00:51:27   2021-01-01 00:57:20   \n",
       "12      13        15  2021-01-01 00:29:05   2021-01-01 00:29:07   \n",
       "\n",
       "   store_and_fwd_flag  RatecodeID  PULocationID  DOLocationID  \\\n",
       "0                   N           1            43           151   \n",
       "1                   N           1           166           239   \n",
       "2                   N           1            41            42   \n",
       "3                   N           1           168            75   \n",
       "4                   N           2           265           265   \n",
       "5                   N           2           265           265   \n",
       "6                   N           5           265           265   \n",
       "7                   N           1            75            75   \n",
       "8                   N           1           225           225   \n",
       "9                   N           1           225           265   \n",
       "10                  N           1            74            60   \n",
       "11                  N           1            42            41   \n",
       "12                  N           5            42           264   \n",
       "\n",
       "    passenger_count  trip_distance  ...  extra  mta_tax  tip_amount  \\\n",
       "0                 1           1.01  ...    0.5      0.5        0.00   \n",
       "1                 1           2.53  ...    0.5      0.5        2.81   \n",
       "2                 1           1.12  ...    0.5      0.5        1.00   \n",
       "3                 1           1.99  ...    0.5      0.5        0.00   \n",
       "4                 3           0.00  ...    0.0     -0.5        0.00   \n",
       "5                 3           0.00  ...    0.0      0.5        0.00   \n",
       "6                 1           0.00  ...    0.0      0.0       36.06   \n",
       "7                 6           0.45  ...    0.5      0.5        0.96   \n",
       "8                 1           0.00  ...    0.5      0.5        0.00   \n",
       "9                 1          12.19  ...    0.5      0.5        2.75   \n",
       "10                1           5.48  ...    0.5      0.5        0.00   \n",
       "11                2           0.90  ...    0.5      0.5        0.00   \n",
       "12                1           0.09  ...    0.0      0.0        2.06   \n",
       "\n",
       "    tolls_amount  ehail_fee  improvement_surcharge  total_amount  \\\n",
       "0              0        NaN                    0.3          6.80   \n",
       "1              0        NaN                    0.3         16.86   \n",
       "2              0        NaN                    0.3          8.30   \n",
       "3              0        NaN                    0.3          9.30   \n",
       "4              0        NaN                   -0.3        -52.80   \n",
       "5              0        NaN                    0.3         52.80   \n",
       "6              0        NaN                    0.3        216.36   \n",
       "7              0        NaN                    0.3          5.76   \n",
       "8              0        NaN                    0.3          3.80   \n",
       "9              0        NaN                    0.3         42.05   \n",
       "10             0        NaN                    0.3         19.30   \n",
       "11             0        NaN                    0.3          7.30   \n",
       "12             0        NaN                    0.3         12.36   \n",
       "\n",
       "    payment_type  trip_type  congestion_surcharge  \n",
       "0              2          1                  0.00  \n",
       "1              1          1                  2.75  \n",
       "2              1          1                  0.00  \n",
       "3              2          1                  0.00  \n",
       "4              3          1                  0.00  \n",
       "5              2          1                  0.00  \n",
       "6              1          2                  0.00  \n",
       "7              1          1                  0.00  \n",
       "8              2          1                  0.00  \n",
       "9              1          1                  0.00  \n",
       "10             2          1                  0.00  \n",
       "11             1          1                  0.00  \n",
       "12             1          2                  0.00  \n",
       "\n",
       "[13 rows x 21 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the trip_raw_source_data.csv includes a more detailed information about each trip\n",
    "trip_raw_data = pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/tripdata_raw_source_data.csv\")\n",
    "trip_raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>measure_datetime</th>\n",
       "      <th>pedestrians</th>\n",
       "      <th>cars</th>\n",
       "      <th>trucks</th>\n",
       "      <th>bikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>2021-01-01 00:15:56</td>\n",
       "      <td>20323</td>\n",
       "      <td>12134</td>\n",
       "      <td>233</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41</td>\n",
       "      <td>2021-01-01 11:25:59</td>\n",
       "      <td>1323</td>\n",
       "      <td>1234</td>\n",
       "      <td>136</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42</td>\n",
       "      <td>2021-01-01 00:45:57</td>\n",
       "      <td>32321</td>\n",
       "      <td>32321</td>\n",
       "      <td>2324</td>\n",
       "      <td>5342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>2020-12-31 23:57:51</td>\n",
       "      <td>23212</td>\n",
       "      <td>23212</td>\n",
       "      <td>3457</td>\n",
       "      <td>434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>43</td>\n",
       "      <td>2021-01-01 17:16:36</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>3435</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>74</td>\n",
       "      <td>2021-01-01 00:16:36</td>\n",
       "      <td>23223</td>\n",
       "      <td>23223</td>\n",
       "      <td>7853</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>75</td>\n",
       "      <td>2021-01-01 05:19:14</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>322</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>166</td>\n",
       "      <td>2021-01-01 00:26:31</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>3453</td>\n",
       "      <td>677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>168</td>\n",
       "      <td>2021-01-01 00:57:46</td>\n",
       "      <td>10323</td>\n",
       "      <td>80323</td>\n",
       "      <td>6445</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>225</td>\n",
       "      <td>2021-01-01 00:58:32</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>3433</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>225</td>\n",
       "      <td>2021-01-01 18:39:57</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>223</td>\n",
       "      <td>23235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>265</td>\n",
       "      <td>2021-01-01 00:51:27</td>\n",
       "      <td>70323</td>\n",
       "      <td>70323</td>\n",
       "      <td>4343</td>\n",
       "      <td>2323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>265</td>\n",
       "      <td>2021-01-01 00:29:05</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>4343</td>\n",
       "      <td>3254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>265</td>\n",
       "      <td>2021-01-01 00:29:05</td>\n",
       "      <td>10323</td>\n",
       "      <td>10323</td>\n",
       "      <td>1388</td>\n",
       "      <td>6342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    LocationID     measure_datetime  pedestrians   cars  trucks  bikes\n",
       "0           41  2021-01-01 00:15:56        20323  12134     233    233\n",
       "1           41  2021-01-01 11:25:59         1323   1234     136    423\n",
       "2           42  2021-01-01 00:45:57        32321  32321    2324   5342\n",
       "3           42  2020-12-31 23:57:51        23212  23212    3457    434\n",
       "4           43  2021-01-01 17:16:36        10323  10323    3435   2323\n",
       "5           74  2021-01-01 00:16:36        23223  23223    7853   1214\n",
       "6           75  2021-01-01 05:19:14        10323  10323     322    532\n",
       "7          166  2021-01-01 00:26:31        10323  10323    3453    677\n",
       "8          168  2021-01-01 00:57:46        10323  80323    6445    567\n",
       "9          225  2021-01-01 00:58:32        10323  10323    3433    232\n",
       "10         225  2021-01-01 18:39:57        10323  10323     223  23235\n",
       "11         265  2021-01-01 00:51:27        70323  70323    4343   2323\n",
       "12         265  2021-01-01 00:29:05        10323  10323    4343   3254\n",
       "13         265  2021-01-01 00:29:05        10323  10323    1388   6342"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new_york_location_statistics_data.csv has measurment of pedestrians, cars, trucks, bikes traffic information collected for that hour or a certain location. \n",
    "# You can use data of that hour, or aggregate a few days to give you a more stable data.\n",
    "location_raw_data = pd.read_csv(\"https://azurefeathrstorage.blob.core.windows.net/public/sample_data/new_york_location_statistics_data.csv\")\n",
    "location_raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Features with Feathr\n",
    "\n",
    "In Feathr, a feature is viewed as a function, mapping from entity id or key, and timestamp to a feature value. For more details on feature definition, please refer to the [Feathr Feature Definition Guide](https://github.com/linkedin/feathr/blob/main/docs/concepts/feature-definition.md)\n",
    "\n",
    "\n",
    "1. The typed key (a.k.a. entity id) identifies the subject of feature, e.g. a user id, 123.\n",
    "2. The feature name is the aspect of the entity that the feature is indicating, e.g. the age of the user.\n",
    "3. The feature value is the actual value of that aspect at a particular time, e.g. the value is 30 at year 2022.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in some cases, such as features defined on top of request data, may have no entity key or timestamp.\n",
    "It is merely a function/transformation executing against request data at runtime.\n",
    "For example, the day of week of the request, which is calculated by converting the request UNIX timestamp.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Sources Section with UDFs\n",
    "A feature source is needed for anchored features that describes the raw data in which the feature values are computed from. See the python documentation to get the details on each input column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, DataFrame\n",
    "def feathr_udf_day_calc(df: DataFrame) -> DataFrame:\n",
    "    from pyspark.sql.functions import dayofweek, dayofyear, col\n",
    "    df = df.withColumn(\"fare_amount_cents\", col(\"fare_amount\")*100)\n",
    "    return df\n",
    "\n",
    "trip_data_batch_source = HdfsSource(name=\"nycTaxiBatchSource\",\n",
    "                          path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/tripdata_raw_source_data.csv\",\n",
    "                          event_timestamp_column=\"lpep_dropoff_datetime\",\n",
    "                          preprocessing=feathr_udf_day_calc,\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Anchors and Features\n",
    "A feature is called an anchored feature when the feature is directly extracted from the source data, rather than computed on top of other features. The latter case is called derived feature.\n",
    "\n",
    "Here we define a few features on trip_data_batch_source first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the key so know how to join the transformed features into your observation.\n",
    "# Our observation data is keyed by TripID, and our features are describing trip entity, so we should use TripID here as well.\n",
    "trip_id = TypedKey(key_column=\"TripID\",\n",
    "                       key_column_type=ValueType.INT32,\n",
    "                       description=\"trip id for each taxi ride\",\n",
    "                       full_name=\"nyc_taxi.TripID\")\n",
    "\n",
    "f_trip_distance = Feature(name=\"f_trip_distance\",\n",
    "                          key=trip_id,\n",
    "                          feature_type=FLOAT, \n",
    "                          transform=\"trip_distance\")\n",
    "\n",
    "f_trip_time_duration = Feature(name=\"f_trip_time_duration\",\n",
    "                               key=trip_id,\n",
    "                               feature_type=INT32,\n",
    "                               transform=\"(to_unix_timestamp(lpep_dropoff_datetime) - to_unix_timestamp(lpep_pickup_datetime))/60\")\n",
    "\n",
    "f_is_long_trip_distance = Feature(name=\"f_is_long_trip_distance\",\n",
    "                                  key=trip_id,\n",
    "                                  feature_type=BOOLEAN,\n",
    "                                  transform=\"cast_float(trip_distance)>30\")\n",
    "f_day_of_week = Feature(name=\"f_day_of_week\",\n",
    "                        key=trip_id,\n",
    "                        feature_type=INT32,\n",
    "                        transform=\"dayofweek(lpep_dropoff_datetime)\")\n",
    "\n",
    "features = [\n",
    "    f_trip_distance,\n",
    "    f_trip_time_duration,\n",
    "    f_is_long_trip_distance,\n",
    "    f_day_of_week\n",
    "]\n",
    "\n",
    "request_anchor = FeatureAnchor(name=\"trip_source_data\",\n",
    "                               source=trip_data_batch_source,\n",
    "                               features=features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Window aggregation features\n",
    "\n",
    "For window aggregation features, see the supported fields below:\n",
    "\n",
    "Note that the `agg_func` should be any of these:\n",
    "\n",
    "| Aggregation Type | Input Type | Description |\n",
    "| --- | --- | --- |\n",
    "|SUM, COUNT, MAX, MIN, AVG\t|Numeric|Applies the the numerical operation on the numeric inputs. |\n",
    "|MAX_POOLING, MIN_POOLING, AVG_POOLING\t| Numeric Vector | Applies the max/min/avg operation on a per entry bassis for a given a collection of numbers.|\n",
    "|LATEST| Any |Returns the latest not-null values from within the defined time window |\n",
    "\n",
    "\n",
    "After you have defined features and sources, bring them together to build an anchor:\n",
    "\n",
    "\n",
    "Note that if the data source is from the observation data, the `source` section should be `INPUT_CONTEXT` to indicate the source of those defined anchors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_source = HdfsSource(name=\"nyc_location_stats\",\n",
    "                          path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/new_york_location_statistics_data.csv\",\n",
    "                          event_timestamp_column=\"lpep_dropoff_datetime\",\n",
    "                          # preprocessing=feathr_udf_day_calc,\n",
    "                          timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\n",
    "\n",
    "# \n",
    "location_id = TypedKey(key_column=\"LocationID\",\n",
    "                       key_column_type=ValueType.INT32,\n",
    "                       description=\"location id in NYC\",\n",
    "                       full_name=\"nyc_taxi.location_id\")\n",
    "agg_features = [Feature(name=\"f_location_avg_fare\",\n",
    "                        key=location_id,\n",
    "                        feature_type=FLOAT,\n",
    "                        transform=WindowAggTransformation(agg_expr=\"cast_float(pedestrians)\",\n",
    "                                                          agg_func=\"AVG\",\n",
    "                                                          window=\"90d\")),\n",
    "                Feature(name=\"f_location_max_fare\",\n",
    "                        key=location_id,\n",
    "                        feature_type=FLOAT,\n",
    "                        transform=WindowAggTransformation(agg_expr=\"cast_float(cars)\",\n",
    "                                                          agg_func=\"MAX\",\n",
    "                                                          window=\"90d\")),\n",
    "                Feature(name=\"f_location_total_fare_cents\",\n",
    "                        key=location_id,\n",
    "                        feature_type=FLOAT,\n",
    "                        transform=WindowAggTransformation(agg_expr=\"bikes\",\n",
    "                                                          agg_func=\"SUM\",\n",
    "                                                          window=\"90d\")),\n",
    "                ]\n",
    "\n",
    "agg_anchor = FeatureAnchor(name=\"aggregationFeatures\",\n",
    "                           source=batch_source,\n",
    "                           features=agg_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Features Section\n",
    "Derived features are the features that are computed from other features. They could be computed from anchored features, or other derived features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_trip_time_distance = DerivedFeature(name=\"f_trip_time_distance\",\n",
    "                                      key=trip_id,\n",
    "                                      feature_type=FLOAT,\n",
    "                                      input_features=[\n",
    "                                          f_trip_distance, f_trip_time_duration],\n",
    "                                      transform=\"f_trip_distance * f_trip_time_duration\")\n",
    "\n",
    "f_trip_time_rounded = DerivedFeature(name=\"f_trip_time_rounded\",\n",
    "                                     key=trip_id,\n",
    "                                     feature_type=INT32,\n",
    "                                     input_features=[f_trip_time_duration],\n",
    "                                     transform=\"f_trip_time_duration % 10\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we need to build those features so that it can be consumed later. Note that we have to build both the \"anchor\" and the \"derived\" features (which is not anchored to a source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.build_features(anchor_list=[agg_anchor, request_anchor], derived_feature_list=[\n",
    "                      f_trip_time_distance, f_trip_time_rounded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training data using point-in-time correct feature join\n",
    "\n",
    "A training dataset usually contains entity id columns, multiple feature columns, event timestamp column and label/target column. \n",
    "\n",
    "To create a training dataset using Feathr, one needs to provide a feature join configuration file to specify\n",
    "what features and how these features should be joined to the observation data. \n",
    "\n",
    "To learn more on this topic, please refer to [Point-in-time Correctness](https://github.com/linkedin/feathr/blob/main/docs/concepts/point-in-time-join.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-10 12:56:17.328 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:59 - Uploading /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feathr_pyspark_driver.py to cloud..\n",
      "2022-05-10 12:56:17.329 | INFO     | feathr._synapse_submission:upload_file:347 - Uploading file feathr_pyspark_driver.py\n",
      "2022-05-10 12:56:18.191 | INFO     | feathr._synapse_submission:upload_file:353 - /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feathr_pyspark_driver.py is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/feathr_pyspark_driver.py\n",
      "2022-05-10 12:56:18.192 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:62 - /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feathr_pyspark_driver.py is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/feathr_pyspark_driver.py\n",
      "2022-05-10 12:56:18.209 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:59 - Uploading /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_join_conf/feature_join.conf to cloud..\n",
      "2022-05-10 12:56:18.210 | INFO     | feathr._synapse_submission:upload_file:347 - Uploading file feature_join.conf\n",
      "2022-05-10 12:56:18.586 | INFO     | feathr._synapse_submission:upload_file:353 - /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_join_conf/feature_join.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/feature_join.conf\n",
      "2022-05-10 12:56:18.587 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:62 - /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_join_conf/feature_join.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/feature_join.conf\n",
      "2022-05-10 12:56:18.587 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:59 - Uploading /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_conf/ to cloud..\n",
      "2022-05-10 12:56:18.588 | INFO     | feathr._synapse_submission:upload_file_to_workdir:335 - Uploading folder /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_conf/\n",
      "2022-05-10 12:56:18.589 | INFO     | feathr._synapse_submission:upload_file:347 - Uploading file auto_generated_request_features.conf\n",
      "2022-05-10 12:56:18.959 | INFO     | feathr._synapse_submission:upload_file:353 - /private/var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_conf/auto_generated_request_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_request_features.conf\n",
      "2022-05-10 12:56:18.960 | INFO     | feathr._synapse_submission:upload_file:347 - Uploading file auto_generated_anchored_features.conf\n",
      "2022-05-10 12:56:19.330 | INFO     | feathr._synapse_submission:upload_file:353 - /private/var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_conf/auto_generated_anchored_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_anchored_features.conf\n",
      "2022-05-10 12:56:19.331 | INFO     | feathr._synapse_submission:upload_file:347 - Uploading file auto_generated_derived_features.conf\n",
      "2022-05-10 12:56:19.712 | INFO     | feathr._synapse_submission:upload_file:353 - /private/var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_conf/auto_generated_derived_features.conf is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_derived_features.conf\n",
      "2022-05-10 12:56:19.713 | INFO     | feathr._synapse_submission:upload_or_get_cloud_path:62 - /var/folders/c2/fhs5jthx53q80vhsmkjhysq4000gby/T/tmppuqtzwg_/feature_conf/ is uploaded to location: abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_request_features.conf,abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_anchored_features.conf,abfss://feathrazuretest3fs@feathrazuretest3storage.dfs.core.windows.net/feathr_getting_started/auto_generated_derived_features.conf\n",
      "2022-05-10 12:56:19.714 | INFO     | feathr._envvariableutil:get_environment_variable:66 - S3_ACCESS_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.714 | INFO     | feathr._envvariableutil:get_environment_variable:66 - S3_SECRET_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.715 | INFO     | feathr._envvariableutil:get_environment_variable:66 - ADLS_ACCOUNT is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.715 | INFO     | feathr._envvariableutil:get_environment_variable:66 - ADLS_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.716 | INFO     | feathr._envvariableutil:get_environment_variable:66 - BLOB_ACCOUNT is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.716 | INFO     | feathr._envvariableutil:get_environment_variable:66 - BLOB_KEY is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.717 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_TABLE is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.717 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_USER is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.718 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_PASSWORD is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.718 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_DRIVER is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.718 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_AUTH_FLAG is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.719 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_TOKEN is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.742 | INFO     | feathr._envvariableutil:get_environment_variable:66 - JDBC_SF_PASSWORD is not set in the environment variables, fetching the value from Key Vault\n",
      "2022-05-10 12:56:19.743 | INFO     | feathr._synapse_submission:submit_feathr_job:102 - Uploading jar from wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar to cloud for running job: feathr_getting_started_feathr_feature_join_job\n",
      "2022-05-10 12:56:19.743 | INFO     | feathr._synapse_submission:upload_file_to_workdir:330 - Skipping file wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar as it's already in the cloud\n",
      "2022-05-10 12:56:19.744 | INFO     | feathr._synapse_submission:submit_feathr_job:105 - wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar is uploaded to wasbs://public@azurefeathrstorage.blob.core.windows.net/feathr-assembly-LATEST.jar for running job: feathr_getting_started_feathr_feature_join_job\n",
      "2022-05-10 12:56:20.723 | INFO     | feathr._synapse_submission:submit_feathr_job:121 - See submitted job here: https://web.azuresynapse.net/en-us/monitoring/sparkapplication\n",
      "2022-05-10 12:56:20.848 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:56:50.965 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:57:21.082 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:57:51.199 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:58:21.336 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:58:51.450 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:59:21.554 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 12:59:51.664 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:00:21.855 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:00:52.001 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:01:22.223 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:01:52.344 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:02:22.499 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:02:52.614 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:03:22.724 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:03:52.824 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: not_started\n",
      "2022-05-10 13:04:22.977 | INFO     | feathr._synapse_submission:wait_for_completion:131 - Current Spark job status: starting\n"
     ]
    },
    {
     "ename": "TimeoutError",
     "evalue": "Timeout waiting for job to complete",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb Cell 36'\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=9'>10</a>\u001b[0m settings \u001b[39m=\u001b[39m ObservationSettings(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=10'>11</a>\u001b[0m     observation_path\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/green_tripdata_2020-04_with_index.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=11'>12</a>\u001b[0m     event_timestamp_column\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlpep_dropoff_datetime\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=12'>13</a>\u001b[0m     timestamp_format\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myyyy-MM-dd HH:mm:ss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=13'>14</a>\u001b[0m client\u001b[39m.\u001b[39mget_offline_features(observation_settings\u001b[39m=\u001b[39msettings,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=14'>15</a>\u001b[0m                             feature_query\u001b[39m=\u001b[39mfeature_query,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=15'>16</a>\u001b[0m                             output_path\u001b[39m=\u001b[39moutput_path)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathrcli/data/feathr_user_workspace/nyc_driver_demo.ipynb#ch0000033?line=16'>17</a>\u001b[0m client\u001b[39m.\u001b[39;49mwait_job_to_finish(timeout_sec\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m)\n",
      "File \u001b[0;32m~/IdeaProjects/feathr_sample/feathr_project/feathr/client.py:594\u001b[0m, in \u001b[0;36mFeathrClient.wait_job_to_finish\u001b[0;34m(self, timeout_sec)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/client.py?line=590'>591</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait_job_to_finish\u001b[39m(\u001b[39mself\u001b[39m, timeout_sec: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m300\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/client.py?line=591'>592</a>\u001b[0m     \u001b[39m\"\"\"Waits for the job to finish in a blocking way unless it times out\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/client.py?line=592'>593</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/client.py?line=593'>594</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeathr_spark_laucher\u001b[39m.\u001b[39;49mwait_for_completion(timeout_sec):\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/client.py?line=594'>595</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/client.py?line=595'>596</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/IdeaProjects/feathr_sample/feathr_project/feathr/_synapse_submission.py:139\u001b[0m, in \u001b[0;36m_FeathrSynapseJobLauncher.wait_for_completion\u001b[0;34m(self, timeout_seconds)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/_synapse_submission.py?line=136'>137</a>\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m30\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/_synapse_submission.py?line=137'>138</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/hnlin/IdeaProjects/feathr_sample/feathr_project/feathr/_synapse_submission.py?line=138'>139</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mTimeout waiting for job to complete\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTimeoutError\u001b[0m: Timeout waiting for job to complete"
     ]
    }
   ],
   "source": [
    "if client.spark_runtime == 'databricks':\n",
    "    output_path = 'dbfs:/feathrazure_test.avro'\n",
    "else:\n",
    "    # output_path = feathr_output_path\n",
    "    output_path = \"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/test_output.avro\"\n",
    "\n",
    "\n",
    "feature_query = FeatureQuery(\n",
    "    feature_list=[\"f_location_avg_fare\", \"f_trip_time_rounded\", \"f_is_long_trip_distance\", \"f_location_total_fare_cents\"], key=location_id)\n",
    "settings = ObservationSettings(\n",
    "    observation_path=\"wasbs://public@azurefeathrstorage.blob.core.windows.net/sample_data/green_tripdata_2020-04_with_index.csv\",\n",
    "    event_timestamp_column=\"lpep_dropoff_datetime\",\n",
    "    timestamp_format=\"yyyy-MM-dd HH:mm:ss\")\n",
    "client.get_offline_features(observation_settings=settings,\n",
    "                            feature_query=feature_query,\n",
    "                            output_path=output_path)\n",
    "client.wait_job_to_finish(timeout_sec=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the result and show the result\n",
    "\n",
    "Let's use the helper function `get_result_df` to download the result and view it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_df(client: FeathrClient) -> pd.DataFrame:\n",
    "    \"\"\"Download the job result dataset from cloud as a Pandas dataframe.\"\"\"\n",
    "    res_url = client.get_job_result_uri(block=True, timeout_sec=600)\n",
    "    tmp_dir = tempfile.TemporaryDirectory()\n",
    "    client.feathr_spark_laucher.download_result(result_path=res_url, local_folder=tmp_dir.name)\n",
    "    dataframe_list = []\n",
    "    # assuming the result are in avro format\n",
    "    for file in glob.glob(os.path.join(tmp_dir.name, '*.avro')):\n",
    "        dataframe_list.append(pdx.read_avro(file))\n",
    "    vertical_concat_df = pd.concat(dataframe_list, axis=0)\n",
    "    tmp_dir.cleanup()\n",
    "    return vertical_concat_df\n",
    "\n",
    "df_res = get_result_df(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a machine learning model\n",
    "After getting all the features, let's train a machine learning model with the converted feature by Feathr:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "final_df = df_res\n",
    "final_df.drop([\"lpep_pickup_datetime\", \"lpep_dropoff_datetime\",\n",
    "              \"store_and_fwd_flag\"], axis=1, inplace=True, errors='ignore')\n",
    "final_df.fillna(0, inplace=True)\n",
    "final_df['fare_amount'] = final_df['fare_amount'].astype(\"float64\")\n",
    "\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(final_df.drop([\"fare_amount\"], axis=1),\n",
    "                                                    final_df[\"fare_amount\"],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42)\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(train_x, train_y)\n",
    "\n",
    "y_predict = model.predict(test_x)\n",
    "\n",
    "y_actual = test_y.values.flatten().tolist()\n",
    "rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
    "\n",
    "sum_actuals = sum_errors = 0\n",
    "\n",
    "for actual_val, predict_val in zip(y_actual, y_predict):\n",
    "    abs_error = actual_val - predict_val\n",
    "    if abs_error < 0:\n",
    "        abs_error = abs_error * -1\n",
    "\n",
    "    sum_errors = sum_errors + abs_error\n",
    "    sum_actuals = sum_actuals + actual_val\n",
    "\n",
    "mean_abs_percent_error = sum_errors / sum_actuals\n",
    "print(\"Model MAPE:\")\n",
    "print(mean_abs_percent_error)\n",
    "print()\n",
    "print(\"Model Accuracy:\")\n",
    "print(1 - mean_abs_percent_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialize feature value into offline/online storage\n",
    "\n",
    "While Feathr can compute the feature value from the feature definition on-the-fly at request time, it can also pre-compute\n",
    "and materialize the feature value to offline and/or online storage. \n",
    "\n",
    "We can push the generated features to the online store like below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backfill_time = BackfillTime(start=datetime(\n",
    "    2020, 5, 20), end=datetime(2020, 5, 20), step=timedelta(days=1))\n",
    "redisSink = RedisSink(table_name=\"nycTaxiDemoFeature\")\n",
    "settings = MaterializationSettings(\"nycTaxiTable\",\n",
    "                                   backfill_time=backfill_time,\n",
    "                                   sinks=[redisSink],\n",
    "                                   feature_names=[\"f_location_avg_fare\", \"f_location_max_fare\"])\n",
    "\n",
    "client.materialize_features(settings)\n",
    "client.wait_job_to_finish(timeout_sec=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then get the features from the online store (Redis):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching feature value for online inference\n",
    "\n",
    "For features that are already materialized by the previous step, their latest value can be queried via the client's\n",
    "`get_online_features` or `multi_get_online_features` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = client.get_online_features('nycTaxiDemoFeature', '265', [\n",
    "                                 'f_location_avg_fare', 'f_location_max_fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.multi_get_online_features(\"nycTaxiDemoFeature\", [\"239\", \"265\"], [\n",
    "                                 'f_location_avg_fare', 'f_location_max_fare'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering and Fetching features\n",
    "\n",
    "We can also register the features with an Apache Atlas compatible service, such as Azure Purview, and share the registered features across teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.register_features()\n",
    "client.list_registered_features(project_name=\"feathr_getting_started\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8195c8d1fa07eaa1b0361875405ef431aa19553d6947870567c6a96acd8cc147"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('sample_feathr': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
